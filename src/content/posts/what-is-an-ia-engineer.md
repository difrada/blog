---
title: "What Is an AI Engineer, Really?"
description: "AI engineering is not a checklist of tools. It is about reasoning under constraints, building systems that scale, and understanding fundamentals beyond current trends."
author: "sebastian-franco"
pubDate: 2026-02-20
tags: ["ai", "engineering", "llms", "systems", "fundamentals"]
category: "reads"
lang: "en"
draft: false
---

## The Checklist Problem

Recently, I came across a post listing the skills an AI Engineer “should have.”

It was not wrong — but it felt incomplete.

The list included:

- LLMs (at a high level)  
- Context engineering  
- Function calling  
- Observability  
- Structured outputs  
- Cost considerations  
- Some traditional software engineering to “build the product”  

All of that is relevant. But assuming that this checklist defines the role is where the problem begins.

Because before discussing artificial intelligence, there is a more fundamental question:

**What does it really mean to be an engineer?**

## Engineering Before AI

Herbert A. Simon once wrote:

> “Engineering is the art of devising solutions to problems under constraints.”

That definition matters.

An engineer is not defined by the tools they know, but by their ability to reason, abstract, and solve new problems — especially when there are no clear recipes.

This is why engineering education is long and demanding. It is built on mathematics, physics, systems thinking, and rigorous technical foundations. Not to memorize solutions, but to develop the capacity to create them when the problem does not resemble anything seen before.

Reducing engineering to a set of currently fashionable technologies misses what truly matters.

And something very similar happens with artificial intelligence.

## AI Is Bigger Than LLMs

AI is not synonymous with LLMs.

The rise of generative AI has brought the field to the center of public attention, but artificial intelligence has existed for decades. It encompasses:

- Machine learning  
- Deep learning  
- Optimization  
- Statistics  
- Evaluation methodologies  
- Control systems  
- Distributed training and inference  
- Data engineering and feature systems  
- Robustness and reliability under real-world constraints  

Generative models are a powerful layer — not the entire discipline.

Defining an AI Engineer as someone who orchestrates prompts and tools is like defining a civil engineer as someone who knows how to use AutoCAD.

It confuses implementation with foundation.

## Where the Confusion Shows Up

This confusion usually appears later.

It appears when:

- Systems do not scale.  
- Models fail to generalize.  
- Costs explode under production load.  
- Edge cases break critical flows.  
- Evaluation is superficial.  
- Infrastructure cannot support growth.  

Building AI products is not just about calling APIs. It requires understanding trade-offs, constraints, architecture, and failure modes.

It requires engineering.

## So What Is Often Overlooked?

When the role of “AI Engineer” is reduced to a checklist, several dimensions tend to disappear:

- Mathematical maturity  
- Statistical reasoning  
- Systems architecture  
- Distributed computing fundamentals  
- Infrastructure awareness  
- Evaluation rigor  
- Optimization under constraints  
- Long-term maintainability  

Tools change. APIs evolve. Frameworks disappear.

Fundamentals do not.

## The Real Question

Maybe the real question is not:

“What tools should an AI Engineer know?”

But rather:

“Can this person design, reason about, and build intelligent systems under real-world constraints?”

Because AI engineering is not about trends.

It is about building systems that work — and continue working — when the hype moves on.